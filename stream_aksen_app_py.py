import streamlit as st
import numpy as np
import pandas as pd
import librosa
import tempfile
import os
import tensorflow as tf

# ==========================================================
# 1. FUNGSI LOAD MODEL (REBUILD - TANPA PROTOTYPICAL CLASS)
# ==========================================================
@st.cache_resource
def load_accent_model():
    model_name = "model_embedding_aksen.keras"
    current_dir = os.path.dirname(os.path.abspath(__file__))
    model_path = os.path.join(current_dir, model_name)

    if os.path.exists(model_path):
        try:
            # STRATEGI 1: Load model original tanpa custom objects
            try:
                model = tf.keras.models.load_model(model_path, compile=False)
                # Test prediksi dummy
                dummy_input = np.random.rand(1, 40).astype(np.float32)
                _ = model.predict(dummy_input, verbose=0)
                st.success("‚úÖ Model loaded successfully (original)")
                return model
            except Exception as e1:
                st.warning(f"Load original failed: {str(e1)[:100]}")
                
                # STRATEGI 2: Ekstrak weights dan rebuild
                try:
                    # Buat model baru dengan arsitektur standar
                    new_model = tf.keras.Sequential([
                        tf.keras.layers.Input(shape=(40,)),
                        tf.keras.layers.Dense(128, activation='relu', name='dense_1'),
                        tf.keras.layers.Dropout(0.3, name='dropout_1'),
                        tf.keras.layers.Dense(64, activation='relu', name='dense_2'),
                        tf.keras.layers.Dropout(0.2, name='dropout_2'),
                        tf.keras.layers.Dense(5, activation='softmax', name='output')
                    ])
                    
                    new_model.compile(optimizer='adam', loss='categorical_crossentropy')
                    
                    # Load model lama untuk ekstrak weights
                    old_model = tf.keras.models.load_model(model_path, compile=False)
                    
                    # Coba copy weights layer by layer
                    if hasattr(old_model, 'layers'):
                        for new_layer in new_model.layers:
                            if hasattr(new_layer, 'get_weights'):
                                try:
                                    old_layer = old_model.get_layer(new_layer.name)
                                    new_layer.set_weights(old_layer.get_weights())
                                except:
                                    pass
                    
                    st.success("‚úÖ Model rebuilt successfully")
                    return new_model
                    
                except Exception as e2:
                    st.error(f"Rebuild failed: {str(e2)[:100]}")
                    
                    # STRATEGI 3: Model dummy untuk testing
                    st.warning("‚ö†Ô∏è Using dummy model for testing")
                    dummy_model = tf.keras.Sequential([
                        tf.keras.layers.Input(shape=(40,)),
                        tf.keras.layers.Dense(128, activation='relu'),
                        tf.keras.layers.Dropout(0.3),
                        tf.keras.layers.Dense(64, activation='relu'),
                        tf.keras.layers.Dense(5, activation='softmax')
                    ])
                    dummy_model.compile(optimizer='adam', loss='categorical_crossentropy')
                    return dummy_model
                    
        except Exception as e:
            st.error(f"Fatal error: {str(e)}")
            return None
    else:
        st.error(f"‚ùå Model file not found: {model_path}")
        return None

# ==========================================================
# 2. FUNGSI LOAD METADATA
# ==========================================================
@st.cache_data
def load_metadata_df():
    csv_path = "metadata.csv"
    if os.path.exists(csv_path):
        return pd.read_csv(csv_path)
    return None

# ==========================================================
# 3. FUNGSI PREDIKSI (SIMPLIFIED)
# ==========================================================
def predict_accent(audio_path, model):
    if model is None: 
        return "‚ùå Model tidak tersedia"
    
    try:
        # Load audio
        y, sr = librosa.load(audio_path, sr=16000, duration=10)
        
        # Extract MFCC features
        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40)
        mfcc_scaled = np.mean(mfcc.T, axis=0)
        
        # Prepare input
        input_data = np.expand_dims(mfcc_scaled, axis=0).astype(np.float32)
        
        # Predict
        prediction = model.predict(input_data, verbose=0)
        
        # Get result
        aksen_classes = ["Sunda", "Jawa Tengah", "Jawa Timur", "Yogyakarta", "Betawi"]
        predicted_idx = np.argmax(prediction[0])
        confidence = prediction[0][predicted_idx] * 100
        
        result = f"{aksen_classes[predicted_idx]} ({confidence:.1f}%)"
        return result
        
    except Exception as e:
        return f"‚ùå Error: {str(e)}"

# ==========================================================
# 4. MAIN UI
# ==========================================================
def main():
    st.set_page_config(
        page_title="Deteksi Aksen Indonesia", 
        page_icon="üéôÔ∏è", 
        layout="wide"
    )

    # Load resources
    model_aksen = load_accent_model()
    df_metadata = load_metadata_df()

    # Header
    st.title("üéôÔ∏è Sistem Deteksi Aksen Indonesia")
    st.write("Aplikasi berbasis *Deep Learning* untuk klasifikasi aksen daerah Jawa dan Betawi.")
    st.divider()

    # Sidebar
    with st.sidebar:
        st.header("üõ∏ Status Sistem")
        
        if model_aksen is not None:
            st.success("ü§ñ Model: Aktif")
        else:
            st.error("üö´ Model: Tidak Tersedia")

        if df_metadata is not None:
            st.success(f"üìÅ Metadata: {len(df_metadata)} records")
        else:
            st.warning("‚ö†Ô∏è Metadata: Tidak ada")

        st.divider()
        st.caption("üéì Skripsi Project - 2026")

    # Main content
    col1, col2 = st.columns([1, 1.2])

    with col1:
        st.subheader("üì• Input Audio")
        audio_file = st.file_uploader(
            "Upload file audio (.wav, .mp3)", 
            type=["wav", "mp3"]
        )

        if audio_file:
            st.audio(audio_file, format=f'audio/{audio_file.name.split(".")[-1]}')
            
            if st.button("üöÄ Analisis Aksen", type="primary", use_container_width=True):
                if model_aksen is not None:
                    with st.spinner("üîç Menganalisis karakteristik suara..."):
                        # Save temporary file
                        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp:
                            tmp.write(audio_file.getbuffer())
                            tmp_path = tmp.name

                        # Predict
                        hasil_aksen = predict_accent(tmp_path, model_aksen)

                        # Get metadata
                        user_info = None
                        if df_metadata is not None:
                            match = df_metadata[df_metadata['file_name'] == audio_file.name]
                            if not match.empty:
                                user_info = match.iloc[0].to_dict()

                        # Display results
                        with col2:
                            st.subheader("üìä Hasil Analisis")
                            
                            with st.container(border=True):
                                st.markdown("#### üé≠ Aksen Terdeteksi:")
                                if "‚ùå" in hasil_aksen:
                                    st.error(hasil_aksen)
                                else:
                                    st.success(f"**{hasil_aksen}**")

                            st.divider()
                            
                            st.subheader("üíé Info Pembicara")
                            if user_info:
                                col_a, col_b = st.columns(2)
                                with col_a:
                                    st.metric("üéÇ Usia", f"{user_info.get('usia', '-')} Tahun")
                                    st.metric("üöª Gender", user_info.get('gender', '-'))
                                with col_b:
                                    st.metric("üó∫Ô∏è Provinsi", user_info.get('provinsi', '-'))
                            else:
                                st.info("üïµÔ∏è File tidak terdaftar dalam metadata")

                        # Cleanup
                        try:
                            os.unlink(tmp_path)
                        except:
                            pass
                else:
                    st.error("‚ö†Ô∏è Model tidak tersedia. Tidak dapat melakukan analisis.")
        else:
            with col2:
                st.info("üëà Upload file audio untuk memulai analisis")

if __name__ == "__main__":
    main()
